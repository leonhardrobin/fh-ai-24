{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leonhardrobin/fh-ai-24/blob/main/AI_WS2425_Exercise_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCDNKWMTnmDy"
      },
      "source": [
        "In this exercise, we will look at classifying the CIFAR10-dataset (i.e., the same images as discussed in the lecture). You can find the individual tasks in the code examples below.\n",
        "\n",
        "You should solve the following tasks:\n",
        "1) randomly show 5 images from the dataset\n",
        "2) randomly show 5 images based on the matrices generated from the dataset\n",
        "3) calculate and apply the average loss and accuracy metrics\n",
        "4) Hyperparameter evaluation: run the model with 3x3 learning rates (0.01, 0.001, 0.0001) and epochs (20, 50, 100) and note the results (i.e., final accuracies of all sets). Make a plot of the best performing hyperparameter configuration (i.e., accuracy (y) over epochs (x))\n",
        "5) Interpret the results of your models, i.e., why are they performing good/bad?\n",
        "\n",
        "1) Import the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjzC2anLnfdl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QPpQUTCnu9I"
      },
      "source": [
        "2) Load the CIFAR10 dataset, which is part of pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dODgI8OpnzLz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b784b4f-29fa-4d73-998a-c9b689caba83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 43221670.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                        download=True)\n",
        "# the labels will be put in a seperate vector as the original is just numbers, but we want text labels\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ab2CuqOzoJOy"
      },
      "source": [
        "Now, lets look into some of the images..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EO8Gv6V7oL9q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "outputId": "94acb05f-f182-49c6-d233-e2476d37c2e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is an image of a deer\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7eebc5925e70>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAwW0lEQVR4nO3dfXCV9Z338c85JzknzyckgTyYhPKgoCLYUsHcti4VVmDndrRy72jbmcWuo6MbnFW225adVqu7O+namda2Q/GPdWU7U7R1p+jovdUqlnC7C26hclPUcgONEh4SIJCnk+Q8Xvcf1myjIL8vJPyS+H45Z8bkfPnmd53rus43J+eczwkFQRAIAICLLOx7AQCAjycGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADAizzfC/igXC6no0ePqrS0VKFQyPdyAABGQRCor69PdXV1CofP/jhn3A2go0ePqqGhwfcyAAAXqL29XfX19We9fswG0Pr16/Wd73xHHR0dWrBggX74wx9q0aJF5/x3paWlkqSKmrjCYbdHQEGmxHldoZBtk0ORlHttOGrqXV7kXj+nvtzUe8GVs5xri4qLTb1/9OPnTfXZqHv/vPyMqXdJSaFzbf0ljabeFVMqnWuj+WP7u9xvfvOGc21eJGLqffr0aefazuOdpt7RfPdjPBfkTL1zOfd6621SGLPVX1JV5VybON1j6n3tddc61772X7829T7Sedy5trAg37k2CAL1dGeG78/PZkzOmp/+9Kdau3atHn/8cS1evFiPPfaYli9frn379mnatGkf+W/f/7NbOBxyH0Af8RDvw/1tT3uFLL0NtZIUMZwU+Xm2XVUQcz/xLbWSPvIh9ZkEYfftDEdsd0Km2zDf/QSSpGjU/XYZ6wFk2c5Inu3OMxyxnD+2P4uHHM9hSQrljL0Na7GsQ5Lzfc/7TPvHeP5Eo+7HrfXctOxO022Ye7//R/+bMXkRwne/+13ddddd+vKXv6wrrrhCjz/+uIqKivQv//IvY/HjAAAT0KgPoFQqpV27dmnZsmX//UPCYS1btkzbt2//UH0ymVRvb++ICwBg8hv1AXTy5Ells1lVV1eP+H51dbU6Ojo+VN/S0qJ4PD584QUIAPDx4P19QOvWrVNPT8/wpb293feSAAAXwag/c1pVVaVIJKLOzpGvluns7FRNTc2H6mOxmGKx2GgvAwAwzo36I6BoNKqFCxdqy5Ytw9/L5XLasmWLmpqaRvvHAQAmqDF57ejatWu1evVqffrTn9aiRYv02GOPKZFI6Mtf/vJY/DgAwAQ0JgPotttu04kTJ/Tggw+qo6NDV199tV588cUPvTABAPDxNWbvnluzZo3WrFlz3v9+MJFxfqNZODzo3Dc/3/pXxyH30lyRqfPJUwnn2j39J0y958x2f9d/aZFt3eVF7ukDkhSbUutc29N3ytT7+DHDu/g79pp6R/MNb7wL0qbexcb0icFB92O8r7fP1DtQ4FxrecOllflNrrK8i9LWOzHonoAiSUFgeFOsMeIyLPc3Z1dXlZt6HzvunoSQzbovPHA8pLy/Cg4A8PHEAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHgxth9kfwEChSTHqI10xhCXY8zBCGSIWDH2jua5fwzFyW5bvErbO4eda2dMqzD1/kRNpan+VNo96mWgd8DUWzn3QzgStR3uA4Put3lqqN/Uu7u721QfDrv/rhi45qCcR71lHZItXieXc4+cea+5e2nOeJuksrb67j73Y6W8sMDUO8+wnSWFUVPvSMg9Wikv4r7uIBdIOnecEY+AAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF6M2yy4cDhwjlbLZs+dOfTfte7ZR5IUBIYgpnDW1HsoSBoWYmqtY8c6nWtTAwlT70umxU31yZPuWX2Jnm5T70hhkXNtKmW4vSUlU+65dEHWtu+tTPlu1rxDQwabNWfOZux6Z3O23jnj7+anu92zAKsbq029C6Lu+zOZGDT1zmbcewch99vQ9TjhERAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwItxG8UTUkYhx0iRiCFdJxy2RfGk0oYID2OSSM4Q3xIx7qq2Q8eca989dMTU++p5s0z1ybcPGarTpt7ZIONcm8naongCQ29b+I3McTmu54IkKbDFAoUtvY3rttwyQWD7fTgUuEcIhYwnZ8S4nUND7nFTR450mHqfnj3dubbbEAkkSdE89/uVrPkgPzceAQEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8GL9ZcKGcc/5VviEMLpNzz4+SpFzgniEVkS1nLi/kfvPnZFv3qcSAc+2v39pv6v3JT19uqr+sscq5Nha13Ya9affsuFzYlpEWZNzrCwuKTL0Vsv3ul0y6Z43lGTO7LLlnucDWPMi511eWV5h6ZzPu2X49PadNvSMR43aG3M/PpPE+6Pgp93M5nbGtu/GSqc617Se6nGuDnNv9Jo+AAABejPoA+ta3vqVQKDTiMnfu3NH+MQCACW5M/gR35ZVX6pVXXvnvH2KI/AYAfDyMyWTIy8tTTU3NWLQGAEwSY/Ic0P79+1VXV6eZM2fqS1/6kg4dOvsHkiWTSfX29o64AAAmv1EfQIsXL9bGjRv14osvasOGDWpra9NnP/tZ9fX1nbG+paVF8Xh8+NLQ0DDaSwIAjEOjPoBWrlypP//zP9f8+fO1fPly/fu//7u6u7v1s5/97Iz169atU09Pz/Clvb19tJcEABiHxvzVAeXl5brssst04MCBM14fi8UUi8XGehkAgHFmzN8H1N/fr4MHD6q2tnasfxQAYAIZ9QH0la98Ra2trXrnnXf0n//5n/r85z+vSCSiL3zhC6P9owAAE9io/wnu8OHD+sIXvqCuri5NnTpVn/nMZ7Rjxw5Nneoe+SBJQRDINX0mk3OPTMll3KN1JKkwL9+59tKGS2y9Cwuda48YYjAkqfP4oHPt3vYOU+/tb+wx1c/+xAzn2tJi259jT510f9VkpDBq6j2Udj+uZs2w7fuiIvd9L0lvv/2We3HYdhta4qZyhnNNksIh9/q6avfIJkk63dPtXHvy1ElT7zzDeS9J2bD7bZgxxPZIUs5QX1dfbepd31jvXHvqtR3OtblcTqdPJ85ZN+oD6Omnnx7tlgCASYgsOACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAF2P+cQznK5sLKRQKOdWmsu55U+GsLQuusc4942vxXPfMM0kqjLnnTR2ZNsXUe2fYPT/q3c4Tpt6vvr7XVF9SUu5c+yf/Y5Gp9/Mvb3Ou7U255+NJUp7b4SdJigS2fK9FC+aZ6jvb33WuPdWfMvUOQu53A+Fc2tS7sMD9GG+stWXBnTp53Lk2J8POlJS2/moedu+fztj2T2lpgXPtjIZZpt6DaUsOoHtf11oeAQEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvBi/UTzZQI5JPMrJPU4iP2yM4qlyjwf55AxbFM/U8mLn2gMd7rEjktTefti59lCHLaakraPbVP9i66+da2/5n//T1PsLtyx3rn11W6upd8eJU861XYfaTL01zxaZMre+2rl2x96Dpt6ZiHvUiyWORZIKI+7H1pSiqKl3JpV0Lw5FTL1l3M5Q4H6/Uhi1rWXmJTXOtZdOrzf1fn7La861p0+fdq4NHG8PHgEBALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvBi/WXA5OWfByZA3pcAW8hTJZpxrKwtKTL0r82LOtf2xfFPv2VMrnGsPdXSZencMDJrqf3fEvf+zz/1vU+8li65yrv1fN15r6n26zz1r7Fh7p6l3qO+EqX7BzDrn2v2/d88BlKSOhPsxHhjPn7Ji95y5gV737D1JGkwknGsjYdtdXZBJm+pL893P5U9dcZmpd0OV+7n8+7d+Z+q9+43fmupHG4+AAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF6M2yy4IAhLcst4C+Xc52hBYJu5VTH3fLf8tC0nq+vQEefa8sKoqfcV06c71+58130dktQ5MGSqj4Td177/SIep94kX3fPDZtVXm3pfPW+ec+2nP/kpU+94LDDVZ9Lut/mST8029W799dvOtYMZQ+6ipMbGRufaQx0nTb17Uynn2pDxd+3pUwpN9VfMcj/fFi38pKn3O4bz899/2WrqfbKn370433AfFASSsucs4xEQAMAL8wDatm2bbrrpJtXV1SkUCunZZ58dcX0QBHrwwQdVW1urwsJCLVu2TPv37x+t9QIAJgnzAEokElqwYIHWr19/xusfffRR/eAHP9Djjz+u119/XcXFxVq+fLmGhmx/tgEATG7m54BWrlyplStXnvG6IAj02GOP6Rvf+IZuvvlmSdKPf/xjVVdX69lnn9Xtt99+YasFAEwao/ocUFtbmzo6OrRs2bLh78XjcS1evFjbt28/479JJpPq7e0dcQEATH6jOoA6Ot57BVN19chXG1VXVw9f90EtLS2Kx+PDl4aGhtFcEgBgnPL+Krh169app6dn+NLe3u57SQCAi2BUB1BNTY0kqbOzc8T3Ozs7h6/7oFgsprKyshEXAMDkN6oDaMaMGaqpqdGWLVuGv9fb26vXX39dTU1No/mjAAATnPlVcP39/Tpw4MDw121tbdq9e7cqKirU2Nio+++/X//wD/+gSy+9VDNmzNA3v/lN1dXV6ZZbbhnNdQMAJjjzANq5c6c+97nPDX+9du1aSdLq1au1ceNGffWrX1UikdDdd9+t7u5ufeYzn9GLL76ogoIC408KyTWKR1n3B3LZ9LnjIf5YJuNePzCQMPXO9rvHYBRki0y9T3e5R9Sc6us29c4P2yKHwobUmVSBLQLleMZ9LZ1vHTb1fuv3necu+oOaylJT7/qpFab66bXu9ZfPco+/kaSaSvfeQ9mIqXe/4fz5zW/fMvVOpdPOtfXTKk29VzS5xzBJUt0ldc617x4+aur98v/Z6Vx7+ESPqXdQ4B6vEwTuJ7JrrXkALVmy5CObh0IhPfLII3rkkUesrQEAHyPeXwUHAPh4YgABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8MEfxXCyhIHBNglPOMEYHI4ZgMkk73zlw7qI/mHFJlan3FbXV5y76gyHZMuwGUinn2qKYex6UJCUD2+8t4ZB7flgu457vJUkpQ9ZYXoEtx2wo3732nX7bJ/m+c7rbVP/G/neday9rqDX1vvEzn3auXTy73tR7+67dzrXVRa5n/Hsqy6Y41y769NWm3pfU227D//zNm861O3b/ztS7e8D9XA7yDAetpFzO/f4wFBr9LDgeAQEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvBi3UTxyjHJ4r9a9NBS1bfKhni7n2tfeesvUe8qUuHNtOGSL4jl26qRzbSxsi6iZUlpgqg8b4kHyIra1HD16zLk2k7XdhqF897Wkw7YYmUi+LTJlKOUeUXTgncOm3p+8tM65dsp8WxRP49Qi59qrZ9eYeqcNkVA1Jbbz/lTXCVP9/31zv3Ntb8bUWrlooXut9RiX+2IssT1E8QAAxjUGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADAi3GbBRf6w38u8gP3HK6wLSpJBQVR59pj3adNvfceds/sqp1WYeo9ZMiEKit0z+uSpFzMlgXX359wro1HY6bexTW1zrVHTx439Q4M+W5DWUMgoaRkcshUHy90Pw6bLp9h6t0wxf1uoLjQdpdRFHXP05teO83UWxH3YyWUSZpalxS5569J0rWLrnau3fLGQVPvru4+59pwyHYchgwRhpZ4Tlc8AgIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeDFuo3gUlhyTeBTOuMfOFOTbZm71lCnuxcY4lgPHOpxr05GcqXdJRblzbUq9pt6Dxu0MIvnOtZWFxabeQyH3SJvItKmm3omEewSKbLtH0XJb1Mv82XXOtYsabL3zcu5RSSdPd5l6h/Pco3jKyspMvbNZ93N50LIvJeXnUqb64pj7XelAf7+pdzjkfnBFcrassawhX8cSxeNayyMgAIAXDCAAgBfmAbRt2zbddNNNqqurUygU0rPPPjvi+jvuuEOhUGjEZcWKFaO1XgDAJGEeQIlEQgsWLND69evPWrNixQodO3Zs+PLUU09d0CIBAJOP+UUIK1eu1MqVKz+yJhaLqaam5rwXBQCY/MbkOaCtW7dq2rRpmjNnju699151dZ39lTPJZFK9vb0jLgCAyW/UB9CKFSv04x//WFu2bNE//dM/qbW1VStXrlT2LJ/Q2dLSong8PnxpaGgY7SUBAMahUX8f0O233z78/1dddZXmz5+vWbNmaevWrVq6dOmH6tetW6e1a9cOf93b28sQAoCPgTF/GfbMmTNVVVWlAwcOnPH6WCymsrKyERcAwOQ35gPo8OHD6urqUm1t7Vj/KADABGL+E1x/f/+IRzNtbW3avXu3KioqVFFRoYcfflirVq1STU2NDh48qK9+9auaPXu2li9fPqoLBwBMbOYBtHPnTn3uc58b/vr9529Wr16tDRs2aM+ePfrXf/1XdXd3q66uTjfeeKP+/u//XrFYzPRzwnlZhUJuYXB5ee6bETHUSlI2cH+QWF83dlljR7q6Tb0LDZl3uYx7FpgkRYKord411E9SZZUhe09Sedw99yxkzNMrK3I/ZmfXX2LqPaW81FSvZLdz6WBnm6l1Xn6Re+8B9+w9STpy5KhzbSptaq3BpPv+DIfcM+kkqWfItp173/69c23WeL6FQ4b7LMP9lSRFo4b75ZAlNy7QQPLcmXfmAbRkyRIFH5E099JLL1lbAgA+hsiCAwB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4MeqfBzRaItk85yy4/Hz3bLK8sC3HLMi4z+hokDH1zobd64cGB0y9BxNn/gDAM4nJlpE2dUqxqb7rxNk/EfeDqqfY9s/nb3YPuY3H3TPPJCn8EZFTH1QQta27cootC+5UZ7tz7f4gaeo9kHSv78+43yaSVFJe6Vx76vS5s8P+WMqQ15ZO2Y7xZNY9v1CSQvnumWoVleWm3v1D7rd5XqTA1Luywj17MZt1v7/KZbNq6z33/uQREADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADAi3EbxVNZEFM47BaHUVrsHrFSaIxMKciPONcWhwZNvdNpQ7xOvi3+Jut420lSPF5l6l1bV2Oqzw+7R4n8/uB+U+9XXn7FuXbZss+ZeldOiTvXptJpU+/EgO1YGRh07989YFvLqZ5e59rfH+0w9Y7kFTrXFhWX23qn3c/N9o4jpt6dp3pM9dk89yiexoYZpt59KffagSFDsaRUKuFcG2Td44xyObdaHgEBALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvBi3WXArllyuaL7b8irKy5z75hlyyd6rd6+N2lrraGe3c+2xHlt22OnefufakgLbYdDT12eqT+Tcc+lSgW0tv9z2unPtrj37TL2v/dTlzrVXXVpv6p0csu3Pw+2HnGsTfe7ZbpJUEnfPvKusrDT1Li6Z4lybDdyz3SQpnXU/rgoKC0y9Feo2ledSSffihHv+miTlRd2zLqMF+abexWXu+6dqivu+z6Qzam879zHLIyAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBfjNopnbuMlKoy5xUpMKS927hsvNUZy5FLOpV3d7rWSdOSke6RN5RT3uBRJihe7b2fEsI2SlM3ZonimlrhHrOTH3WOVJClaW+FcW1VRZeo9rSTqXNvVfsDUu6fXFpczkBhwrg0CYyZUttC5tCDf/TaRJGXcI4fyI+7rkKSKMveImktqbBFCBYW2SJuTJ3qca08nhky9p9XVOtf25HKm3gX57ttZWup+P5tOp53qeAQEAPDCNIBaWlp0zTXXqLS0VNOmTdMtt9yifftGBjwODQ2publZlZWVKikp0apVq9TZ2TmqiwYATHymAdTa2qrm5mbt2LFDL7/8stLptG688UYl/ijd9YEHHtDzzz+vZ555Rq2trTp69KhuvfXWUV84AGBiMz0H9OKLL474euPGjZo2bZp27dql66+/Xj09PXriiSe0adMm3XDDDZKkJ598Updffrl27Niha6+9dvRWDgCY0C7oOaCenveeeKuoeO+J4F27dimdTmvZsmXDNXPnzlVjY6O2b99+xh7JZFK9vb0jLgCAye+8B1Aul9P999+v6667TvPmzZMkdXR0KBqNqry8fERtdXW1Ojo6ztinpaVF8Xh8+NLQ0HC+SwIATCDnPYCam5u1d+9ePf300xe0gHXr1qmnp2f40t7efkH9AAATw3m9D2jNmjV64YUXtG3bNtXX//dHEdfU1CiVSqm7u3vEo6DOzk7V1NScsVcsFlMsFjufZQAAJjDTI6AgCLRmzRpt3rxZr776qmbMmDHi+oULFyo/P19btmwZ/t6+fft06NAhNTU1jc6KAQCTgukRUHNzszZt2qTnnntOpaWlw8/rxONxFRYWKh6P684779TatWtVUVGhsrIy3XfffWpqauIVcACAEUwDaMOGDZKkJUuWjPj+k08+qTvuuEOS9L3vfU/hcFirVq1SMpnU8uXL9aMf/WhUFgsAmDxCgTk4amz19vYqHo/rXx+8R0UFbs8NlZeXOPcvLrJlPGUySefa3x20vYDinSPuCRHxclsW3JQS9yy4mNy3UZJCObecp+F6Q21eyD03TpKiEff9WVLknmUlSdl04txFf3C668yv8jybUz22txskUxn34rDtqd2I4TnYSNSWBdfd0+9cG4RsvWvrP+Fcm8zaMtL6k7ZjvK/bPatv7742U++hAvf7t7wK92xEScqk3Y+rvDz3MzmdzujlX2xTT0+PysrOnu9IFhwAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwIvz+jiGiyFeUabiQreIkFiBe+zMyd4e0zq6Tna5F9vSPnTNlXOca2NRS6CNFA7c43WSg4aYF0mZpG1DA0P7dMoWC5RKDTrXJmXbzqHBPufaRL975IwkJQeN25lz3//hfNuxoqz776HJhPvtLUl5+e7xOhnDNkpS2rLv07bEsWTKtpaiUve4nNKyIlPvUyfdY5sK8wtNvbOGGK6+IfdjPJPJOtXxCAgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgxbjNgiuJx1Vc5Jbx1t7e7ty3s7PTtI7CQvdspZkzGk29K8vc86OSg+55UJLU1+OekxUJ2XKvAllztdzzphJ97vlrkmRZujVnbmhoyLn2xGlbFlxfImGqD+W55SJKUl6+bf/EC92Pw8Sg+20iSZnALRNMkkIR99w4STp+2j3XMWe8qwtF3G9vSeofcN//EaVNvStL3e+DcmH321uSOrtPONcmhtyP2WzWLS+SR0AAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC/GbRTP2wfaVFjgFs1x0hCvc0lttWkd1VMrnWtrquKm3qGMezTMUM4W36GcWxSGJOXSGVvrdMpUnzVsZyZj653OuMfOpPvd44kkqTcx4Fx7ossWIZTJ2PZnrMD9d8UCRUy9+wfc43UGc7a7jO5e99slCNmikpIZ9yieSF6+qXdJcampPpt0P1bybbtHn2hwv8/q6LFFQoUC9/OtqMB94dmsW0YWj4AAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXozbLLgjJ06rIOqW3xQNu29GOGILYhpIuGcrJUtsvYOUe35UcjBh6j3Q577u3m73TC1JSqfcs8MkaSjpnnvW3W/r3T/k3nsgacu86x90z8lK2iLsVFRoyxrLL4g510ZjbhmK7+s1ZMENqMDUeyhwPyc6j3eZeg8a9mcoYrurq6+33YZXX3m5c20ubcu86x10P8aTJ2y3obLupRHDfWcQkAUHABjHTAOopaVF11xzjUpLSzVt2jTdcsst2rdv34iaJUuWKBQKjbjcc889o7poAMDEZxpAra2tam5u1o4dO/Tyyy8rnU7rxhtvVCIx8s9Dd911l44dOzZ8efTRR0d10QCAic/0h9EXX3xxxNcbN27UtGnTtGvXLl1//fXD3y8qKlJNTc3orBAAMCld0HNAPT3vPXldUVEx4vs/+clPVFVVpXnz5mndunUaGDj7k+3JZFK9vb0jLgCAye+8XwWXy+V0//3367rrrtO8efOGv//FL35R06dPV11dnfbs2aOvfe1r2rdvn37+85+fsU9LS4sefvjh810GAGCCOu8B1NzcrL179+q1114b8f277757+P+vuuoq1dbWaunSpTp48KBmzZr1oT7r1q3T2rVrh7/u7e1VQ0PD+S4LADBBnNcAWrNmjV544QVt27ZN9fX1H1m7ePFiSdKBAwfOOIBisZhiMff3OAAAJgfTAAqCQPfdd582b96srVu3asaMGef8N7t375Yk1dbWntcCAQCTk2kANTc3a9OmTXruuedUWlqqjo4OSVI8HldhYaEOHjyoTZs26c/+7M9UWVmpPXv26IEHHtD111+v+fPnj8kGAAAmJtMA2rBhg6T33mz6x5588kndcccdikajeuWVV/TYY48pkUiooaFBq1at0je+8Y1RWzAAYHIw/wnuozQ0NKi1tfWCFvS+WGGJYo6ZVp+6aq5z39Odh03rKDA8PxXLt72qva/fPQsu0WfLa0v09TnXDg0Mmnp3G3LmJKnPkNk1aItr0+mEe05W74B7rSQNJt0zu0I5Q6iWpFzItpaCwkLn2uISW85c2pCnl8245TMOM5QPZU+bWg9m3PLGJCk/3/Y8c3fqo+/rPujtd4841wbWLMVMzrm2q9v2NpZoXrFzbTjifv8WcQyZIwsOAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAODFeX8e0Fi7bOYsFRUWONVON3x+0NQy90gTSQoy7jE1kTxbHEvGUJ7NusdxSFIQco8p6R1KmXr3GWNKUkHEuTZja62MIetl8BxRUh80YLjNc4a4FEnSkHvMjyRVht1/V4wao3iGBruda3uM6+7tSzjXJnPux6wkhWPu53JOtt6DxnPiSOcp59renm5T71hRiXNtQWm5qfdgryHiy3T+uNXyCAgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgxbjNgquvrVZJkVvWUyTknlE0ZUqZaR25bMy5dqiv19Q7FHbLupOkaNS9VpKCsCGDK2T7PSSUHzXVRw0RUpnAlqeXF3Gvt/62lZfnvp2hPFv3aMy2naF898y7k4NpU+/D3X3Otf1ZW6ZaxlBeWV1t6l1Y4J6R1mfJPJOUl2fMpctz3z/RYlsmYVe3+9pnTa0x9S4pdF/30GC/c23aMeiSR0AAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC/GbRRPEKQUBBGn2mzWfY6GwrYIlCCXc65NpVKm3uGI+7rz8my7Kp12j2MJG6N4ou7pHZKkXM49eiTsfnO/V29YerEtQUhlhe63eX6+LSrJNWbqfYmU+3Hb2WmLnUmF3G+YbGbQ1Ls8Xu5cWzFlmql3Ou1+mwwODph6Dw64xxNJUkmZ4eAKbFE8maz7dp44cdzUu6Gmwrk2HCl1rk2nM249nTsCADCKGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC/GbRbc0FC/ImG3PKFs1j2fqrjAFgiWS7vnuw0NJU29LXltQ0NDpt6W/KhQyNRag0nbWgwxZkpk3fL/3heKuu/PYtlyAMOG+qJC23EVCsdM9Yl+9yyzqlkzTb2rDWs/3XHU1LuvL+FcOzhky5nrOnnauba/z5btVlVZbqovLXevP3HKfd2SFDYEHp482WXqXWiIMKyvq3OuTZEFBwAYz0wDaMOGDZo/f77KyspUVlampqYm/eIXvxi+fmhoSM3NzaqsrFRJSYlWrVqlzs7OUV80AGDiMw2g+vp6ffvb39auXbu0c+dO3XDDDbr55pv15ptvSpIeeOABPf/883rmmWfU2tqqo0eP6tZbbx2ThQMAJjbTc0A33XTTiK//8R//URs2bNCOHTtUX1+vJ554Qps2bdINN9wgSXryySd1+eWXa8eOHbr22mtHb9UAgAnvvJ8Dymazevrpp5VIJNTU1KRdu3YpnU5r2bJlwzVz585VY2Ojtm/fftY+yWRSvb29Iy4AgMnPPIB++9vfqqSkRLFYTPfcc482b96sK664Qh0dHYpGoyr/wKtBqqur1dHRcdZ+LS0tisfjw5eGhgbzRgAAJh7zAJozZ452796t119/Xffee69Wr16tt95667wXsG7dOvX09Axf2tvbz7sXAGDiML8PKBqNavbs2ZKkhQsX6te//rW+//3v67bbblMqlVJ3d/eIR0GdnZ2qqak5a79YLKZYzPaeCADAxHfB7wPK5XJKJpNauHCh8vPztWXLluHr9u3bp0OHDqmpqelCfwwAYJIxPQJat26dVq5cqcbGRvX19WnTpk3aunWrXnrpJcXjcd15551au3atKioqVFZWpvvuu09NTU28Ag4A8CGmAXT8+HH9xV/8hY4dO6Z4PK758+frpZde0p/+6Z9Kkr73ve8pHA5r1apVSiaTWr58uX70ox+d18J6ek8qnXb701xxYZFz33DOvVaSgmzOuTZrqJWkbMYtrkKSMhn32B5JChvydbI527oTKfd1S1JxlXuEx5VX235Z+X/79jnXdhx809S7IGY4PfJsUTzGZCWl3BOhzLFNZcXua6+urjb1zouccq4tLZti6q3APbbpEkOMjCQFge0Y7+41RP0Egal3fn6+c204YvujVtepbufasniZc23aMYrHNICeeOKJj7y+oKBA69ev1/r16y1tAQAfQ2TBAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvDCnYY+14A8xFQODScM/cp+jIUOtZIviSQ/aIlBSg+75KgNDtiiewaR7lMiQMVonmc6a6vMM/Qct+11SMuV+u6Ss6w4b4oyM0S2GZUuS0hn3taeMzZNJ9+MwYoybSqXd12LZl9beYcO+lOxRPK7RM5KUydqOQ0vElzVWKyTD/ZthG9N/ONeCc8QOhYJzVVxkhw8f5kPpAGASaG9vV319/VmvH3cDKJfL6ejRoyotLVXojwI1e3t71dDQoPb2dpWVuYfiTTRs5+TxcdhGie2cbEZjO4MgUF9fn+rq6hQOn/2vTuPuT3DhcPgjJ2ZZWdmk3vnvYzsnj4/DNkps52RzodsZj8fPWcOLEAAAXjCAAABeTJgBFIvF9NBDDykWc/uQuomK7Zw8Pg7bKLGdk83F3M5x9yIEAMDHw4R5BAQAmFwYQAAALxhAAAAvGEAAAC8mzABav369PvGJT6igoECLFy/Wf/3Xf/le0qj61re+pVAoNOIyd+5c38u6INu2bdNNN92kuro6hUIhPfvssyOuD4JADz74oGpra1VYWKhly5Zp//79fhZ7Ac61nXfccceH9u2KFSv8LPY8tbS06JprrlFpaammTZumW265Rfv27RtRMzQ0pObmZlVWVqqkpESrVq1SZ2enpxWfH5ftXLJkyYf25z333ONpxednw4YNmj9//vCbTZuamvSLX/xi+PqLtS8nxAD66U9/qrVr1+qhhx7Sb37zGy1YsEDLly/X8ePHfS9tVF155ZU6duzY8OW1117zvaQLkkgktGDBAq1fv/6M1z/66KP6wQ9+oMcff1yvv/66iouLtXz5cg0N2UJdfTvXdkrSihUrRuzbp5566iKu8MK1traqublZO3bs0Msvv6x0Oq0bb7xRiURiuOaBBx7Q888/r2eeeUatra06evSobr31Vo+rtnPZTkm66667RuzPRx991NOKz099fb2+/e1va9euXdq5c6duuOEG3XzzzXrzzTclXcR9GUwAixYtCpqbm4e/zmazQV1dXdDS0uJxVaProYceChYsWOB7GWNGUrB58+bhr3O5XFBTUxN85zvfGf5ed3d3EIvFgqeeesrDCkfHB7czCIJg9erVwc033+xlPWPl+PHjgaSgtbU1CIL39l1+fn7wzDPPDNe8/fbbgaRg+/btvpZ5wT64nUEQBH/yJ38S/PVf/7W/RY2RKVOmBP/8z/98UffluH8ElEqltGvXLi1btmz4e+FwWMuWLdP27ds9rmz07d+/X3V1dZo5c6a+9KUv6dChQ76XNGba2trU0dExYr/G43EtXrx40u1XSdq6daumTZumOXPm6N5771VXV5fvJV2Qnp4eSVJFRYUkadeuXUqn0yP259y5c9XY2Dih9+cHt/N9P/nJT1RVVaV58+Zp3bp1GhgY8LG8UZHNZvX0008rkUioqanpou7LcRdG+kEnT55UNptVdXX1iO9XV1frd7/7nadVjb7Fixdr48aNmjNnjo4dO6aHH35Yn/3sZ7V3716Vlpb6Xt6o6+jokKQz7tf3r5ssVqxYoVtvvVUzZszQwYMH9Xd/93dauXKltm/frkgk4nt5ZrlcTvfff7+uu+46zZs3T9J7+zMajaq8vHxE7UTen2faTkn64he/qOnTp6uurk579uzR1772Ne3bt08///nPPa7W7re//a2ampo0NDSkkpISbd68WVdccYV279590fbluB9AHxcrV64c/v/58+dr8eLFmj59un72s5/pzjvv9LgyXKjbb799+P+vuuoqzZ8/X7NmzdLWrVu1dOlSjys7P83Nzdq7d++Ef47yXM62nXfffffw/1911VWqra3V0qVLdfDgQc2aNetiL/O8zZkzR7t371ZPT4/+7d/+TatXr1Zra+tFXcO4/xNcVVWVIpHIh16B0dnZqZqaGk+rGnvl5eW67LLLdODAAd9LGRPv77uP236VpJkzZ6qqqmpC7ts1a9bohRde0K9+9asRH5tSU1OjVCql7u7uEfUTdX+ebTvPZPHixZI04fZnNBrV7NmztXDhQrW0tGjBggX6/ve/f1H35bgfQNFoVAsXLtSWLVuGv5fL5bRlyxY1NTV5XNnY6u/v18GDB1VbW+t7KWNixowZqqmpGbFfe3t79frrr0/q/Sq996m/XV1dE2rfBkGgNWvWaPPmzXr11Vc1Y8aMEdcvXLhQ+fn5I/bnvn37dOjQoQm1P8+1nWeye/duSZpQ+/NMcrmcksnkxd2Xo/qShjHy9NNPB7FYLNi4cWPw1ltvBXfffXdQXl4edHR0+F7aqPmbv/mbYOvWrUFbW1vwH//xH8GyZcuCqqqq4Pjx476Xdt76+vqCN954I3jjjTcCScF3v/vd4I033gjefffdIAiC4Nvf/nZQXl4ePPfcc8GePXuCm2++OZgxY0YwODjoeeU2H7WdfX19wVe+8pVg+/btQVtbW/DKK68En/rUp4JLL700GBoa8r10Z/fee28Qj8eDrVu3BseOHRu+DAwMDNfcc889QWNjY/Dqq68GO3fuDJqamoKmpiaPq7Y713YeOHAgeOSRR4KdO3cGbW1twXPPPRfMnDkzuP766z2v3ObrX/960NraGrS1tQV79uwJvv71rwehUCj45S9/GQTBxduXE2IABUEQ/PCHPwwaGxuDaDQaLFq0KNixY4fvJY2q2267LaitrQ2i0WhwySWXBLfddltw4MAB38u6IL/61a8CSR+6rF69OgiC916K/c1vfjOorq4OYrFYsHTp0mDfvn1+F30ePmo7BwYGghtvvDGYOnVqkJ+fH0yfPj246667JtwvT2faPknBk08+OVwzODgY/NVf/VUwZcqUoKioKPj85z8fHDt2zN+iz8O5tvPQoUPB9ddfH1RUVASxWCyYPXt28Ld/+7dBT0+P34Ub/eVf/mUwffr0IBqNBlOnTg2WLl06PHyC4OLtSz6OAQDgxbh/DggAMDkxgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABe/H/9ZWCHVeQ5vgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "example = 3465\n",
        "image, label = trainset[example] #since each element of the trainset list is itself a tuple with the image details, and then the label\n",
        "print(\"this is an image of a \" + classes[(trainset[example])[1]]) # first index into tuple in trainset, then the 2nd value (label), and then the classes\n",
        "plt.imshow(image)\n",
        "\n",
        "# TASK 1: randomly show 5 images from the trainingset, i.e., the random number generator should draw a value between 0 and the size of the set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGhCotvYojqD"
      },
      "source": [
        "We utilize the pytorch transform module to create matrices of color values from the images..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PtyhAGipnzx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d154eca-6772-4ee2-d1ae-e0a8c31779db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "datasetT = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYDILyP_pw2D"
      },
      "source": [
        "Now we have matrices with the dimensions 3x32x32 (i.e., 32*32 pixels and 3 RGB colors). We can assess one of the training examples with the following code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8s3pV2Bpv_L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f27af0b3-b32f-4145-9ca0-22146f6abe9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of image matrix: torch.Size([3, 32, 32])\n",
            "this is an image of a dog\n"
          ]
        }
      ],
      "source": [
        "example = 128\n",
        "imgTensor, label = datasetT[example]\n",
        "print('size of image matrix: ' + str(imgTensor.shape))\n",
        "print(\"this is an image of a \" + classes[(trainset[example])[1]])\n",
        "\n",
        "#TASK 2: similar as above, use matplotlib to visualze 5 images randomly drawn from the dataset (but use the matrices now!)\n",
        "#you should create a numpy array from the tensor, flip dimensions/axis accordingly, and plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djSr2UW5sje8"
      },
      "source": [
        "next, we build a training set (60%), a cross-validation set (20%), and a test set fo the final validation (20%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PL1Zs5iustP0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72a2b514-0f6e-47c0-f026-bbc37b043c77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amount of training examples: 40000\n",
            "amount of cross validation examples: 10000\n"
          ]
        }
      ],
      "source": [
        "#length of training examples.\n",
        "m = 50000\n",
        "\n",
        "#percentage of m dedicated to CV.\n",
        "pCV = 0.2\n",
        "\n",
        "# give the amount of examples dedicated to CV.\n",
        "mCV = int(m*pCV)\n",
        "print(\"amount of training examples: \" + str(m - mCV))\n",
        "print(\"amount of cross validation examples: \" + str(mCV))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LpUFw4Ksw8k"
      },
      "source": [
        "Next, we shuffle the data and create the sets..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_xAe7JXs1jk"
      },
      "outputs": [],
      "source": [
        "def ShuffleAndSPlit(countExamples, percentageCV):\n",
        "  \"\"\" randomly shuffle a training set's indices, then split the indices into training and cross validation sets.\n",
        "   Pass in 'm', length of training set, and 'pCV', the percentage of the training set you would like\n",
        "   to dedicate to cross validation.\"\"\"\n",
        "\n",
        "  # determine size of CV set.\n",
        "  mCV = int(countExamples*percentageCV)\n",
        "\n",
        "  #create random permutation of 0 to m-1 - randomly shuffle all values from 0 to m.\n",
        "  indices = np.random.permutation(countExamples)\n",
        "\n",
        "  #pick first mCV indices for training, and then validation.\n",
        "  return indices[mCV:], indices[:mCV]\n",
        "\n",
        "trainIndices, valIndices = ShuffleAndSPlit(m, pCV)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajUKFUExs-BV"
      },
      "source": [
        "Now, we load the indices into groups for Stochastic Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yaYuPaStJ7k"
      },
      "outputs": [],
      "source": [
        "#We define a batch size and use the SubsetRandomSampler and the DataLoader as given by pytorch: https://pytorch.org/docs/stable/data.html\n",
        "\n",
        "batchSize = 100\n",
        "#First, we create a sampler using our training set\n",
        "trainSampler = SubsetRandomSampler(trainIndices)\n",
        "#The dataloader helps us to draw batchSize randomly sampled examples from our training datasetT\n",
        "trainLoader = DataLoader(datasetT, batchSize, sampler=trainSampler)\n",
        "\n",
        "#The same happens for the validation set...\n",
        "valSampler = SubsetRandomSampler(valIndices)\n",
        "valLoader = DataLoader(datasetT, batchSize, sampler=valSampler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f36xSEwqtWhU"
      },
      "source": [
        "Now we prepare our model - since the data should be a vector, each 3x32x32 image tensor needs to be flattened to a vector of length 3072"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOsp09cutgqU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62f5a936-1257-4649-eb1b-b6472b15907e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dimensions of weight matrix W: torch.Size([10, 3072])\n",
            "Parameter containing:\n",
            "tensor([[-0.0113, -0.0010, -0.0023,  ...,  0.0165,  0.0029, -0.0174],\n",
            "        [ 0.0034, -0.0165,  0.0004,  ..., -0.0009, -0.0082,  0.0119],\n",
            "        [ 0.0015,  0.0138, -0.0130,  ..., -0.0077, -0.0175, -0.0061],\n",
            "        ...,\n",
            "        [ 0.0060, -0.0160, -0.0003,  ...,  0.0008,  0.0028, -0.0037],\n",
            "        [-0.0066, -0.0107,  0.0038,  ...,  0.0032,  0.0004,  0.0167],\n",
            "        [-0.0117, -0.0125,  0.0084,  ...,  0.0046, -0.0105,  0.0125]],\n",
            "       requires_grad=True)\n",
            "dimensions of bias matrix b: torch.Size([10])\n",
            "Parameter containing:\n",
            "tensor([ 0.0001,  0.0176,  0.0044, -0.0174,  0.0017, -0.0150, -0.0165,  0.0079,\n",
            "        -0.0084, -0.0062], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "# this will define the rows of the matrix\n",
        "inputSize = 3*32*32\n",
        "\n",
        "# this will define the columns of the matrix\n",
        "numClasses = 10\n",
        "\n",
        "# create our linear regression model (nn.Linear creates bias vector)\n",
        "model = nn.Linear(inputSize, numClasses)\n",
        "\n",
        "print('dimensions of weight matrix W: ' + str(model.weight.shape))\n",
        "print(model.weight)\n",
        "\n",
        "print('dimensions of bias matrix b: ' + str(model.bias.shape))\n",
        "print(model.bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ihnCFjZuNd8"
      },
      "source": [
        "Now, we take images from one batch of the dataset and put it into the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzmKYfeyuXT8"
      },
      "outputs": [],
      "source": [
        "#this class reshapes the matrices to be compatible, i.e., batchsize times 3072 (32x32x3)\n",
        "#the CIFAR10 class is a subclass of nn.Module, inheriting all its functions\n",
        "class CIFAR10(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(inputSize, numClasses)\n",
        "\n",
        "    def forward(self, xb):\n",
        "        xb = xb.reshape(-1, 3072)\n",
        "        out = self.linear(xb)\n",
        "        return out\n",
        "\n",
        "model = CIFAR10()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WorJeEF0uzJk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b75ee4c6-2d35-4db4-d6d5-ede9c7bd8b9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 3072])\n",
            "torch.Size([10])\n",
            "outputs.shape : torch.Size([100, 10])\n",
            "sample outputs :\n",
            " tensor([[ 0.3946, -0.7205, -0.1211, -0.5564, -0.1897,  0.0311, -0.0996, -0.6287,\n",
            "          0.5235,  0.0565],\n",
            "        [ 0.4079, -0.3870, -0.4696, -0.1545,  0.2441,  0.0638,  0.1505, -0.5208,\n",
            "          0.4919, -0.0318]], grad_fn=<SliceBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(model.linear.weight.shape)\n",
        "print(model.linear.bias.shape)\n",
        "\n",
        "for images, labels in trainLoader:\n",
        "  outputs = model(images)\n",
        "  break\n",
        "\n",
        "print('outputs.shape :', outputs.shape)\n",
        "print('sample outputs :\\n', outputs[:2]) # print 2 out of the 100 rows of the total output vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8RHpu_7vBfb"
      },
      "source": [
        "Stochastic Gradient Descent - Cross Entropy Loss\n",
        "Pytorch will apply softmax automatically"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8ha_NoJu8ak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60cd7278-d0f3-4d58-f0a8-fe4e6d16de87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3414, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "lossFn = F.cross_entropy\n",
        "\n",
        "loss = lossFn(outputs, labels)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9QRazZxvYTU"
      },
      "source": [
        "We train the model using the:\n",
        "\n",
        "Data loaders\n",
        "Model\n",
        "Loss function\n",
        "Optimizer\n",
        "\n",
        "This model will use the training set (xb, yb) to train the parameters, and will evaluate the cost function again for the cross validation set.\n",
        "\n",
        "Let's define a function lossBatch which calculates the loss for some given batch, and performs a gradient update step for ALL the parameters based on that batch if an optimizer is provided. Also, it computes a metric (e.g accuracy) optionally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRMsOmgYvUNc"
      },
      "outputs": [],
      "source": [
        "learningRate = 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n",
        "\n",
        "# recall that items is a list batchSize long of 3x32x32 images. labels is the corresponding labels vector for those images.\n",
        "\n",
        "def lossBatch(model, lossFn, items, labels, opt=None, metric=None):\n",
        "  # calculate the loss of the items given the original labels\n",
        "  preds = model(items)\n",
        "  loss = lossFn(preds, labels)\n",
        "\n",
        "  #Here, the optimization step is performed -\n",
        "  if opt is not None:\n",
        "    # compute gradients: https://pytorch.org/docs/stable/generated/torch.Tensor.backward.html\n",
        "    loss.backward()\n",
        "    # update parameters: https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.step.html\n",
        "    opt.step()\n",
        "    # reset gradients to 0\n",
        "    opt.zero_grad()\n",
        "\n",
        "  metricResult = None\n",
        "  if metric is not None:\n",
        "    metricResult = metric(preds, labels)\n",
        "\n",
        "  return loss.item(), len(items),  metricResult"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQYphbRUvhp8"
      },
      "source": [
        "The above code defines a function, when given the\n",
        "\n",
        "model (linear.nn), the loss function (cross entropy)\n",
        "items (the images matrices for the given batch)\n",
        "labels (the corresponding labels for that batch)\n",
        "and optionally, opt (the optimization algorithm)\n",
        "metric. It returns the loss for the training set for that batch (loss.item())\n",
        "the length of the batch (items)\n",
        "the result of the metric, if given (metricResult)\n",
        "\n",
        "Next, let's define a function that computes and evaluates the total cost on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qm5U5XJ2viT1"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, lossFn, validDL, metric=None):\n",
        "\n",
        "  # pass each batch of the validation set through the model to form a multidimensional list (holding loss, length and metric for each batch)\n",
        "  results = [lossBatch(model, lossFn, items, labels, metric=metric,) for items,labels in validDL]\n",
        "\n",
        "  # separate losses, counts and metrics\n",
        "  losses, nums, metrics = zip(*results)\n",
        "\n",
        "  # total size of the dataset (we keep track of lengths of batches since dataset might not be perfectly divisible by batch size)\n",
        "  total = np.sum(nums)\n",
        "\n",
        "  # find average total loss over all batches in validation (remember these are all vectors doing element wise operations.)\n",
        "  # Now, we have a list of \"losses\", their vector lenghts \"nums\" and the number of total items over all batches\n",
        "\n",
        "  # TASK3: calculate the average loss over the validation set, as well as the average metrics (see below)\n",
        "  avgLoss = 0 # TODO\n",
        "\n",
        "  # if there is a metric passed, compute the average metric\n",
        "  if metric is not None:\n",
        "    # avg of metric accross batches\n",
        "    avgMetric = 0 #TODO\n",
        "\n",
        "  return avgLoss, total, avgMetric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id5VoMQIvtLF"
      },
      "source": [
        "We also need to redefine our metric, accuracy, to operate on a batch of outputs directly as opposed to just getting predictions and labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWd98ERovtqc"
      },
      "outputs": [],
      "source": [
        "def accuracy(outputs, labels):\n",
        "  _, preds = torch.max(outputs, dim=1)\n",
        "  return torch.sum(preds == labels).item() / len(preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhjgolEDvx0U"
      },
      "source": [
        "Accuracy takes in the outputs (batchSize x 10, one output for each class) and labels (1 x batchSize). It then gets the index of the max values for each row of outputs, which is the predicted value for each training example. Then, it sums the boolean matrix created by preds == labels, and divides it by the length of the batch, to get the accuracy of the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBRiQnHovybF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "192da583-51f6-4a6e-eeb5-e86476f9a102"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training set loss:  0\n",
            "validation set loss:  0\n"
          ]
        }
      ],
      "source": [
        "# test the evaluate function on both the training and the validation set\n",
        "Etrain = evaluate(model, lossFn, trainLoader, metric=accuracy)\n",
        "Eval = evaluate(model, lossFn, valLoader, metric=accuracy)\n",
        "print(\"training set loss: \", Etrain[0])\n",
        "print(\"validation set loss: \", Eval[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GEcRGZs2-Gm"
      },
      "source": [
        "Finally, the fit function iterates through the number of desired update steps and improves the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hv52g5unwB6c"
      },
      "outputs": [],
      "source": [
        "def fit(epochs, model, lossFn, opt, trainDL, valDL, metric=None):\n",
        "  #valList will hold our accuracies after each epoch (i.e., update step), where we should see an improvement.\n",
        "  #To start with some \"bad\" accuracy, we initialize it with 10%\n",
        "  valList = [0.10]\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    # training - perform one step gradient descent on each batch, then moves on\n",
        "    # therefore, we use the \"lossBatch\" function defined above\n",
        "    for items, labels in trainDL:\n",
        "      loss,_,lossMetric = lossBatch(model, lossFn, items, labels, opt)\n",
        "\n",
        "    # evaluation on cross validation dataset - after updating over all batches, technically one epoch\n",
        "    # evaluates over all validation batches and then calculates average val loss, as well as the metric (accuracy)\n",
        "    valResult = evaluate(model, lossFn, valDL, metric)\n",
        "    valLoss, total, valMetric = valResult\n",
        "    valList.append(valMetric)\n",
        "    # print progress\n",
        "    if metric is None:\n",
        "      print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, epochs, valLoss))\n",
        "    else:\n",
        "      print('Epoch [{}/{}], Loss: {:.4f}, {}: {:.4f}'.format(epoch + 1, epochs, valLoss, metric.__name__, valMetric))\n",
        "\n",
        "  return valList"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsUCwvj9wF_d"
      },
      "source": [
        "now, we can finally train the model using Stochastic Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aEZNXY9wHgk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7480639-1a29-4625-f5ea-aedf04072270"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.0000, accuracy: 0.0000\n",
            "Epoch [2/5], Loss: 0.0000, accuracy: 0.0000\n",
            "Epoch [3/5], Loss: 0.0000, accuracy: 0.0000\n",
            "Epoch [4/5], Loss: 0.0000, accuracy: 0.0000\n",
            "Epoch [5/5], Loss: 0.0000, accuracy: 0.0000\n"
          ]
        }
      ],
      "source": [
        "#TASK4: Hyperparameter evaluation: run the model with 3x3 learning rates (0.01, 0.001, 0.0001)\n",
        "# and epochs (20, 50, 100) and note the results (i.e., final accuracies of all sets).\n",
        "# Make a plot of the best performing hyperparameter configuration (i.e., accuracy (y) over epochs (x))\n",
        "\n",
        "learningRate = 0.01\n",
        "epochs = 5\n",
        "model = CIFAR10()\n",
        "# we use SDG https://pytorch.org/docs/stable/generated/torch.optim.SGD.html\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n",
        "\n",
        "# we call the fit function, with the desired number of epochs, the model, the loss function,\n",
        "# the just before defined optimizer, the datasets, and the accuracy metric\n",
        "trainList = fit(epochs, model, lossFn, optimizer, trainLoader, valLoader, metric=accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Djxh2ADiwY_t"
      },
      "source": [
        "now, we look at the accuracies of the sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wy1cncRwcat",
        "outputId": "132fddb6-3dbb-43f0-b893-40421e53c861"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=torchvision.transforms.ToTensor())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mA_P85KWwfGl"
      },
      "outputs": [],
      "source": [
        "testLoader = DataLoader(test, batchSize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnVyyLKJwhYc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1afae4c2-f1fc-41bf-9690-766a6a04f886"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test set accuracy: \n",
            " 0\n",
            "cross validation set accuracy: \n",
            " 0\n",
            "training set accuracy: \n",
            " 0\n"
          ]
        }
      ],
      "source": [
        "#TASK5 Interpret the results of your models, i.e., why are they performing good/bad?\n",
        "\n",
        "avgLoss, total, avgMetric = evaluate(model, F.cross_entropy, testLoader, metric=accuracy)\n",
        "print(\"test set accuracy: \\n\", avgMetric)\n",
        "avgLoss, total, avgMetric = evaluate(model, F.cross_entropy, valLoader, metric=accuracy)\n",
        "print(\"cross validation set accuracy: \\n\",avgMetric)\n",
        "avgLoss, total, avgMetric = evaluate(model, F.cross_entropy, trainLoader, metric=accuracy)\n",
        "print(\"training set accuracy: \\n\",avgMetric)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}